{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "authorship_tag": "ABX9TyPgxu8qylxnpOOVKuxxMsh3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhamaadUsman/Model-Notebooks/blob/main/BERT%20For%20Custom%20NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeG2yed7_wEf",
        "outputId": "d12f152c-3ca6-49b0-8ad8-baf0622220f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval[gpu]\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.4)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval[gpu]) (1.2.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.11.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (3.2.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from transformers)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=9188764f8c2983f181ad317ab253642a5964a1ddc8cba677606d747051031c7a\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, seqeval, transformers\n",
            "Successfully installed huggingface-hub-0.17.3 safetensors-0.4.0 seqeval-1.2.2 tokenizers-0.14.1 transformers-4.35.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers seqeval[gpu]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification"
      ],
      "metadata": {
        "id": "_TYZh8Nm_-x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6L1vwtRV_-9A",
        "outputId": "b30fdbbe-6254-40ff-a64b-3d60fa84c640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('/content/output_label_token.xlsx')\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BdBVzvAI__Aj",
        "outputId": "26d1c45f-356b-4a44-b8c2-f268ca282e7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Para #      Token Labels\n",
              "0  para :1       item      O\n",
              "1      NaN         10      O\n",
              "2      NaN          .      O\n",
              "3      NaN                 O\n",
              "4      NaN  directors      O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef822fb1-f49b-4de3-a09b-28fb35a75585\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Para #</th>\n",
              "      <th>Token</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>para :1</td>\n",
              "      <td>item</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>directors</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef822fb1-f49b-4de3-a09b-28fb35a75585')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ef822fb1-f49b-4de3-a09b-28fb35a75585 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ef822fb1-f49b-4de3-a09b-28fb35a75585');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4d7c278e-d742-47b5-bfa9-64f8f2982112\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4d7c278e-d742-47b5-bfa9-64f8f2982112')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4d7c278e-d742-47b5-bfa9-64f8f2982112 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad2710KX__EL",
        "outputId": "dd619eeb-1276-4905-b1ba-29f8cb631ebb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Para #       14\n",
              "Token     24753\n",
              "Labels    24753\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Labels'] = data['Labels'].str.replace('B-Position', 'B-position')"
      ],
      "metadata": {
        "id": "210ow2q7By_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of tags: {}\".format(len(data.Labels.unique())))\n",
        "frequencies = data.Labels.value_counts()\n",
        "frequencies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAW0QRoYBBoP",
        "outputId": "1f68139b-aed9-4397-d228-421eed80a69d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tags: 6\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "O             24441\n",
              "B-position       91\n",
              "I-position       87\n",
              "I-name           58\n",
              "B-name           38\n",
              "B-age            38\n",
              "Name: Labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_excel('/content/output_label_token.xlsx', index=False)\n"
      ],
      "metadata": {
        "id": "7kKaeX5jBBsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label2id = {k: v for v, k in enumerate(data.Labels.unique())}\n",
        "id2label = {v: k for v, k in enumerate(data.Labels.unique())}\n",
        "label2id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9d749jGBBvm",
        "outputId": "b2bd7624-bc34-4801-c144-e1e43ba9d80f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'O': 0,\n",
              " 'B-name': 1,\n",
              " 'I-name': 2,\n",
              " 'B-position': 3,\n",
              " 'I-position': 4,\n",
              " 'B-age': 5}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.fillna(method='ffill')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bqz61Zp2Dey7",
        "outputId": "2edbefef-0da2-46af-91c8-cc8afff0f4ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Para #      Token Labels\n",
              "0  para :1       item      O\n",
              "1  para :1         10      O\n",
              "2  para :1          .      O\n",
              "3  para :1                 O\n",
              "4  para :1  directors      O"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-449f923f-74ac-4417-bd99-20fb42e4d46e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Para #</th>\n",
              "      <th>Token</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>para :1</td>\n",
              "      <td>item</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>para :1</td>\n",
              "      <td>10</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>para :1</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>para :1</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>para :1</td>\n",
              "      <td>directors</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-449f923f-74ac-4417-bd99-20fb42e4d46e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-449f923f-74ac-4417-bd99-20fb42e4d46e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-449f923f-74ac-4417-bd99-20fb42e4d46e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-35f11200-c431-41b0-bd1e-556e82fc53f8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-35f11200-c431-41b0-bd1e-556e82fc53f8')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-35f11200-c431-41b0-bd1e-556e82fc53f8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['sentence'] = data[['Para #','Token','Labels']].groupby(['Para #'])['Token'].transform(lambda x: ' '.join(x))\n",
        "data['word_labels'] = data[['Para #','Token','Labels']].groupby(['Para #'])['Labels'].transform(lambda x: ','.join(x))\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "czNGl7UNDe2o",
        "outputId": "c0f68f9d-c69d-4987-e125-546823df8aca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Para #      Token Labels  \\\n",
              "0  para :1       item      O   \n",
              "1  para :1         10      O   \n",
              "2  para :1          .      O   \n",
              "3  para :1                 O   \n",
              "4  para :1  directors      O   \n",
              "\n",
              "                                            sentence  \\\n",
              "0  item 10 .           directors , executive offi...   \n",
              "1  item 10 .           directors , executive offi...   \n",
              "2  item 10 .           directors , executive offi...   \n",
              "3  item 10 .           directors , executive offi...   \n",
              "4  item 10 .           directors , executive offi...   \n",
              "\n",
              "                                         word_labels  \n",
              "0  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "1  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "2  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "3  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "4  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c793eabc-e8cd-42f3-8ad7-b0ce2b893417\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Para #</th>\n",
              "      <th>Token</th>\n",
              "      <th>Labels</th>\n",
              "      <th>sentence</th>\n",
              "      <th>word_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>para :1</td>\n",
              "      <td>item</td>\n",
              "      <td>O</td>\n",
              "      <td>item 10 .           directors , executive offi...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>para :1</td>\n",
              "      <td>10</td>\n",
              "      <td>O</td>\n",
              "      <td>item 10 .           directors , executive offi...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>para :1</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "      <td>item 10 .           directors , executive offi...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>para :1</td>\n",
              "      <td></td>\n",
              "      <td>O</td>\n",
              "      <td>item 10 .           directors , executive offi...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>para :1</td>\n",
              "      <td>directors</td>\n",
              "      <td>O</td>\n",
              "      <td>item 10 .           directors , executive offi...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c793eabc-e8cd-42f3-8ad7-b0ce2b893417')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c793eabc-e8cd-42f3-8ad7-b0ce2b893417 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c793eabc-e8cd-42f3-8ad7-b0ce2b893417');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-97a03d80-3050-4d92-882c-53ad28f09705\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-97a03d80-3050-4d92-882c-53ad28f09705')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-97a03d80-3050-4d92-882c-53ad28f09705 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data[[\"sentence\", \"word_labels\"]].drop_duplicates().reset_index(drop=True)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FiVCrrx5De6s",
        "outputId": "3cb48558-9b3c-4230-f19c-cd293259b464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  \\\n",
              "0  item 10 .           directors , executive offi...   \n",
              "1  item 10 . directors , executive officers and c...   \n",
              "2  item 10 . directors , executive officers and c...   \n",
              "3  item 10 .             directors , executive of...   \n",
              "4  item 10 . directors , executive officers and c...   \n",
              "\n",
              "                                         word_labels  \n",
              "0  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "1  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "2  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "3  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
              "4  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2f4cbd1e-bf45-44e3-88db-1e8e5d65d937\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>word_labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>item 10 .           directors , executive offi...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>item 10 . directors , executive officers and c...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>item 10 . directors , executive officers and c...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>item 10 .             directors , executive of...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>item 10 . directors , executive officers and c...</td>\n",
              "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f4cbd1e-bf45-44e3-88db-1e8e5d65d937')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2f4cbd1e-bf45-44e3-88db-1e8e5d65d937 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2f4cbd1e-bf45-44e3-88db-1e8e5d65d937');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ebeb1b28-cfe5-4686-a7f8-dd5357c8d803\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ebeb1b28-cfe5-4686-a7f8-dd5357c8d803')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ebeb1b28-cfe5-4686-a7f8-dd5357c8d803 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 128\n",
        "TRAIN_BATCH_SIZE = 2\n",
        "VALID_BATCH_SIZE = 2\n",
        "EPOCHS = 250\n",
        "LEARNING_RATE = 1e-05\n",
        "MAX_GRAD_NORM = 10\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "# # Assuming data['sentence'] contains pre-tokenized sentences\n"
      ],
      "metadata": {
        "id": "qz7QVhnEMtS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
        "    \"\"\"\n",
        "    Word piece tokenization makes it difficult to match word labels\n",
        "    back up with individual word pieces. This function tokenizes each\n",
        "    word one at a time so that it is easier to preserve the correct\n",
        "    label for each subword. It is, of course, a bit slower in processing\n",
        "    time, but it will help our model achieve higher accuracy.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenized_sentence = []\n",
        "    labels = []\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    for word, label in zip(sentence.split(), text_labels.split(\",\")):\n",
        "\n",
        "        # Tokenize the word and count # of subwords the word is broken into\n",
        "        tokenized_word = tokenizer.tokenize(word)\n",
        "        n_subwords = len(tokenized_word)\n",
        "\n",
        "        # Add the tokenized word to the final tokenized word list\n",
        "        tokenized_sentence.extend(tokenized_word)\n",
        "\n",
        "        # Add the same label to the new list of labels `n_subwords` times\n",
        "        labels.extend([label] * n_subwords)\n",
        "\n",
        "    return tokenized_sentence, labels"
      ],
      "metadata": {
        "id": "9aFfeb6UAXa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class dataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.len = len(dataframe)\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # step 1: tokenize (and adapt corresponding labels)\n",
        "        sentence = self.data.sentence[index]\n",
        "        word_labels = self.data.word_labels[index]\n",
        "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
        "\n",
        "        # step 2: add special tokens (and corresponding labels)\n",
        "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
        "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
        "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
        "\n",
        "        # step 3: truncating/padding\n",
        "        maxlen = self.max_len\n",
        "\n",
        "        if (len(tokenized_sentence) > maxlen):\n",
        "          # truncate\n",
        "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
        "          labels = labels[:maxlen]\n",
        "        else:\n",
        "          # pad\n",
        "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
        "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
        "\n",
        "        # step 4: obtain the attention mask\n",
        "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
        "\n",
        "        # step 5: convert tokens to input ids\n",
        "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
        "        label_ids = [label2id[label] for label in labels]\n",
        "        # the following line is deprecated\n",
        "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
        "\n",
        "        return {\n",
        "              'ids': torch.tensor(ids, dtype=torch.long),\n",
        "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
        "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
        "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "metadata": {
        "id": "42muIIB2MtWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 0.9\n",
        "train_dataset = data.sample(frac=train_size,random_state=200)\n",
        "test_dataset = data.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(data.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
        "\n",
        "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
        "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9upHserMtZZ",
        "outputId": "e1a58e4c-6b63-443c-f205-2be280e2fdca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (14, 2)\n",
            "TRAIN Dataset: (13, 2)\n",
            "TEST Dataset: (1, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyV8iZniaJhx",
        "outputId": "6c1a710f-1593-47b5-b417-10ba0614ab24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ids': tensor([  101,  8875,  2184,  1012,  5501,  1010,  3237,  3738,  1998,  5971,\n",
              "         10615,  1012,  1996,  2206,  2795,  4520,  5743,  1996,  2171,  1010,\n",
              "          2287,  1998,  2597,  1997,  2169,  1997,  2256,  3237,  3738,  1998,\n",
              "          5501,  2004,  1997,  2285,  2861,  1010,  2418,  1012,  5501,  1998,\n",
              "          3237,  3738,  2171,  2287,  2597,  4775, 21701, 28522,  4779,  5764,\n",
              "          2708,  3237,  2961,  1010,  2343,  1010,  2708,  3361,  2961,  1998,\n",
              "          2472,  1996,  2206,  5577,  1996,  2449,  3325,  1997,  2169,  1997,\n",
              "          2256,  5501,  1998,  3237,  3738,  1010,  2164,  2060,  5501, 19801,\n",
              "          2218,  1999,  2270,  7316,  3316,  1010,  2065,  2151,  1024,  4775,\n",
              "         21701, 28522,  4779,  1010,  2708,  3237,  2961,  1010,  2708,  3361,\n",
              "          2961,  1998,  2472,  1011,  4775, 21701, 28522,  4779,  2038,  2871,\n",
              "          2086,  1997,  2658,  3325,  1999,  2449,  2458, 13252,  1010,  2892,\n",
              "          3675, 28585,  1998, 19530,  1010,  1998,  2248, 13797]),\n",
              " 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " 'targets': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 1, 2, 0, 5, 0, 3, 4, 4, 0, 3, 0, 3, 4, 4, 4, 3, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0])}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set[0][\"ids\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zH97O-exByQU",
        "outputId": "9ed6d1db-15de-4272-d234-cc1b53557f8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  101,  8875,  2184,  1012,  5501,  1010,  3237,  3738,  1998,  5971,\n",
              "        10615,  1012,  1996,  2206,  2795,  4520,  5743,  1996,  2171,  1010,\n",
              "         2287,  1998,  2597,  1997,  2169,  1997,  2256,  3237,  3738,  1998,\n",
              "         5501,  2004,  1997,  2285,  2861,  1010,  2418,  1012,  5501,  1998,\n",
              "         3237,  3738,  2171,  2287,  2597,  4775, 21701, 28522,  4779,  5764,\n",
              "         2708,  3237,  2961,  1010,  2343,  1010,  2708,  3361,  2961,  1998,\n",
              "         2472,  1996,  2206,  5577,  1996,  2449,  3325,  1997,  2169,  1997,\n",
              "         2256,  5501,  1998,  3237,  3738,  1010,  2164,  2060,  5501, 19801,\n",
              "         2218,  1999,  2270,  7316,  3316,  1010,  2065,  2151,  1024,  4775,\n",
              "        21701, 28522,  4779,  1010,  2708,  3237,  2961,  1010,  2708,  3361,\n",
              "         2961,  1998,  2472,  1011,  4775, 21701, 28522,  4779,  2038,  2871,\n",
              "         2086,  1997,  2658,  3325,  1999,  2449,  2458, 13252,  1010,  2892,\n",
              "         3675, 28585,  1998, 19530,  1010,  1998,  2248, 13797])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print the first 30 tokens and corresponding labels\n",
        "for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[0][\"ids\"][:30]), training_set[0][\"targets\"][:30]):\n",
        "  print('{0:10}  {1}'.format(token, id2label[label.item()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Opw-FPVIByUU",
        "outputId": "51276394-8a25-469c-fd97-de2628c22c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]       O\n",
            "item        O\n",
            "10          O\n",
            ".           O\n",
            "directors   O\n",
            ",           O\n",
            "executive   O\n",
            "officers    O\n",
            "and         O\n",
            "corporate   O\n",
            "governance  O\n",
            ".           O\n",
            "the         O\n",
            "following   O\n",
            "table       O\n",
            "sets        O\n",
            "forth       O\n",
            "the         O\n",
            "name        O\n",
            ",           O\n",
            "age         O\n",
            "and         O\n",
            "position    O\n",
            "of          O\n",
            "each        O\n",
            "of          O\n",
            "our         O\n",
            "executive   O\n",
            "officers    O\n",
            "and         O\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "metadata": {
        "id": "FMnQZ3IQNOYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForTokenClassification.from_pretrained('bert-base-uncased',\n",
        "                                                   num_labels=len(id2label),\n",
        "                                                   id2label=id2label,\n",
        "                                                   label2id=label2id)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7ctsvkPNObz",
        "outputId": "11294426-9b66-4b46-d19e-b371868caa7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForTokenClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
        "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
        "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
        "ids = ids.to(device)\n",
        "mask = mask.to(device)\n",
        "targets = targets.to(device)\n",
        "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "initial_loss = outputs[0]\n",
        "initial_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOQUMcLhCJ6t",
        "outputId": "8bbaf839-b32d-4cc0-9ea4-323580f14f09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.7477, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tr_logits = outputs[1]\n",
        "tr_logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8j_UCEjCJ-0",
        "outputId": "d81431a4-b25e-47db-b0d3-241556ad80fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 128, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
      ],
      "metadata": {
        "id": "NozmECj7Onjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "srw5j89WcxwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
        "def train(epoch):\n",
        "    tr_loss, tr_accuracy = 0, 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    tr_preds, tr_labels = [], []\n",
        "    # put model in training mode\n",
        "    model.train()\n",
        "\n",
        "    for idx, batch in enumerate(training_loader):\n",
        "\n",
        "        ids = batch['ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['mask'].to(device, dtype = torch.long)\n",
        "        targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "        loss, tr_logits = outputs.loss, outputs.logits\n",
        "        tr_loss += loss.item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += targets.size(0)\n",
        "\n",
        "        if idx % 100==0:\n",
        "            loss_step = tr_loss/nb_tr_steps\n",
        "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
        "\n",
        "        # compute training accuracy\n",
        "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "        tr_preds.extend(predictions)\n",
        "        tr_labels.extend(targets)\n",
        "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "        tr_accuracy += tmp_tr_accuracy\n",
        "\n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(\n",
        "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
        "        )\n",
        "\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
        "    print(f\"Training loss epoch: {epoch_loss}\")\n",
        "    print(f\"Training accuracy epoch: {tr_accuracy}\")"
      ],
      "metadata": {
        "id": "XQnYuYtEPGOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Training epoch: {epoch + 1}\")\n",
        "    train(epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VD8VTObtPGRg",
        "outputId": "a3d44cad-04cc-4456-c08d-ef059755000d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch: 1\n",
            "Training loss per 100 training steps: 1.8572938442230225\n",
            "Training loss epoch: 1.794210365840367\n",
            "Training accuracy epoch: 0.19196428571428573\n",
            "Training epoch: 2\n",
            "Training loss per 100 training steps: 1.8485840559005737\n",
            "Training loss epoch: 1.811699628829956\n",
            "Training accuracy epoch: 0.17243303571428573\n",
            "Training epoch: 3\n",
            "Training loss per 100 training steps: 1.800255537033081\n",
            "Training loss epoch: 1.7856673683438982\n",
            "Training accuracy epoch: 0.18303571428571427\n",
            "Training epoch: 4\n",
            "Training loss per 100 training steps: 1.7502318620681763\n",
            "Training loss epoch: 1.8006633009229387\n",
            "Training accuracy epoch: 0.17466517857142858\n",
            "Training epoch: 5\n",
            "Training loss per 100 training steps: 1.82045316696167\n",
            "Training loss epoch: 1.818732840674264\n",
            "Training accuracy epoch: 0.15792410714285715\n",
            "Training epoch: 6\n",
            "Training loss per 100 training steps: 1.7541179656982422\n",
            "Training loss epoch: 1.7974542890276228\n",
            "Training accuracy epoch: 0.17410714285714285\n",
            "Training epoch: 7\n",
            "Training loss per 100 training steps: 1.8510301113128662\n",
            "Training loss epoch: 1.8103744983673096\n",
            "Training accuracy epoch: 0.171875\n",
            "Training epoch: 8\n",
            "Training loss per 100 training steps: 1.7949260473251343\n",
            "Training loss epoch: 1.7828730515071325\n",
            "Training accuracy epoch: 0.18582589285714285\n",
            "Training epoch: 9\n",
            "Training loss per 100 training steps: 1.7403886318206787\n",
            "Training loss epoch: 1.8002773353031702\n",
            "Training accuracy epoch: 0.18080357142857142\n",
            "Training epoch: 10\n",
            "Training loss per 100 training steps: 1.7834155559539795\n",
            "Training loss epoch: 1.8008181367601668\n",
            "Training accuracy epoch: 0.1640625\n",
            "Training epoch: 11\n",
            "Training loss per 100 training steps: 1.7914376258850098\n",
            "Training loss epoch: 1.79400668825422\n",
            "Training accuracy epoch: 0.18024553571428573\n",
            "Training epoch: 12\n",
            "Training loss per 100 training steps: 1.755312204360962\n",
            "Training loss epoch: 1.7908729655402047\n",
            "Training accuracy epoch: 0.18136160714285715\n",
            "Training epoch: 13\n",
            "Training loss per 100 training steps: 1.8242626190185547\n",
            "Training loss epoch: 1.789140020098005\n",
            "Training accuracy epoch: 0.18470982142857142\n",
            "Training epoch: 14\n",
            "Training loss per 100 training steps: 1.7655518054962158\n",
            "Training loss epoch: 1.7969091108867101\n",
            "Training accuracy epoch: 0.20089285714285715\n",
            "Training epoch: 15\n",
            "Training loss per 100 training steps: 1.7853362560272217\n",
            "Training loss epoch: 1.7886605092457362\n",
            "Training accuracy epoch: 0.19029017857142858\n",
            "Training epoch: 16\n",
            "Training loss per 100 training steps: 1.7918922901153564\n",
            "Training loss epoch: 1.8062597513198853\n",
            "Training accuracy epoch: 0.16573660714285715\n",
            "Training epoch: 17\n",
            "Training loss per 100 training steps: 1.7918506860733032\n",
            "Training loss epoch: 1.8006878239767892\n",
            "Training accuracy epoch: 0.17410714285714285\n",
            "Training epoch: 18\n",
            "Training loss per 100 training steps: 1.8306163549423218\n",
            "Training loss epoch: 1.805043339729309\n",
            "Training accuracy epoch: 0.16517857142857142\n",
            "Training epoch: 19\n",
            "Training loss per 100 training steps: 1.8102656602859497\n",
            "Training loss epoch: 1.7885535614831107\n",
            "Training accuracy epoch: 0.20368303571428573\n",
            "Training epoch: 20\n",
            "Training loss per 100 training steps: 1.8003485202789307\n",
            "Training loss epoch: 1.7978107929229736\n",
            "Training accuracy epoch: 0.17243303571428573\n",
            "Training epoch: 21\n",
            "Training loss per 100 training steps: 1.7358191013336182\n",
            "Training loss epoch: 1.7782096692493983\n",
            "Training accuracy epoch: 0.19810267857142858\n",
            "Training epoch: 22\n",
            "Training loss per 100 training steps: 1.7566697597503662\n",
            "Training loss epoch: 1.8081741843904768\n",
            "Training accuracy epoch: 0.17633928571428573\n",
            "Training epoch: 23\n",
            "Training loss per 100 training steps: 1.779265284538269\n",
            "Training loss epoch: 1.7974423170089722\n",
            "Training accuracy epoch: 0.16796875\n",
            "Training epoch: 24\n",
            "Training loss per 100 training steps: 1.7950043678283691\n",
            "Training loss epoch: 1.7996311017445155\n",
            "Training accuracy epoch: 0.18861607142857142\n",
            "Training epoch: 25\n",
            "Training loss per 100 training steps: 1.7862403392791748\n",
            "Training loss epoch: 1.803230915750776\n",
            "Training accuracy epoch: 0.19308035714285715\n",
            "Training epoch: 26\n",
            "Training loss per 100 training steps: 1.821621298789978\n",
            "Training loss epoch: 1.7922332457133703\n",
            "Training accuracy epoch: 0.17354910714285715\n",
            "Training epoch: 27\n",
            "Training loss per 100 training steps: 1.7778345346450806\n",
            "Training loss epoch: 1.7953412703105383\n",
            "Training accuracy epoch: 0.18470982142857142\n",
            "Training epoch: 28\n",
            "Training loss per 100 training steps: 1.7509547472000122\n",
            "Training loss epoch: 1.7938037599836076\n",
            "Training accuracy epoch: 0.18247767857142858\n",
            "Training epoch: 29\n",
            "Training loss per 100 training steps: 1.7991477251052856\n",
            "Training loss epoch: 1.8001884732927596\n",
            "Training accuracy epoch: 0.18917410714285715\n",
            "Training epoch: 30\n",
            "Training loss per 100 training steps: 1.754603624343872\n",
            "Training loss epoch: 1.7886799744197301\n",
            "Training accuracy epoch: 0.18638392857142858\n",
            "Training epoch: 31\n",
            "Training loss per 100 training steps: 1.7628722190856934\n",
            "Training loss epoch: 1.7900585957935877\n",
            "Training accuracy epoch: 0.19587053571428573\n",
            "Training epoch: 32\n",
            "Training loss per 100 training steps: 1.819851279258728\n",
            "Training loss epoch: 1.8082876716341292\n",
            "Training accuracy epoch: 0.17801339285714285\n",
            "Training epoch: 33\n",
            "Training loss per 100 training steps: 1.7630159854888916\n",
            "Training loss epoch: 1.7940073353903634\n",
            "Training accuracy epoch: 0.19140625\n",
            "Training epoch: 34\n",
            "Training loss per 100 training steps: 1.8297295570373535\n",
            "Training loss epoch: 1.7971490451267786\n",
            "Training accuracy epoch: 0.18582589285714285\n",
            "Training epoch: 35\n",
            "Training loss per 100 training steps: 1.7628105878829956\n",
            "Training loss epoch: 1.7942883798054285\n",
            "Training accuracy epoch: 0.17912946428571427\n",
            "Training epoch: 36\n",
            "Training loss per 100 training steps: 1.8204632997512817\n",
            "Training loss epoch: 1.8100927897862025\n",
            "Training accuracy epoch: 0.18359375\n",
            "Training epoch: 37\n",
            "Training loss per 100 training steps: 1.7648123502731323\n",
            "Training loss epoch: 1.792802436011178\n",
            "Training accuracy epoch: 0.19754464285714285\n",
            "Training epoch: 38\n",
            "Training loss per 100 training steps: 1.8189359903335571\n",
            "Training loss epoch: 1.7914503301892961\n",
            "Training accuracy epoch: 0.18973214285714285\n",
            "Training epoch: 39\n",
            "Training loss per 100 training steps: 1.8370994329452515\n",
            "Training loss epoch: 1.7888454709734236\n",
            "Training accuracy epoch: 0.19308035714285715\n",
            "Training epoch: 40\n",
            "Training loss per 100 training steps: 1.7973792552947998\n",
            "Training loss epoch: 1.785766295024327\n",
            "Training accuracy epoch: 0.19196428571428573\n",
            "Training epoch: 41\n",
            "Training loss per 100 training steps: 1.774946689605713\n",
            "Training loss epoch: 1.7741086823599679\n",
            "Training accuracy epoch: 0.21875\n",
            "Training epoch: 42\n",
            "Training loss per 100 training steps: 1.7613952159881592\n",
            "Training loss epoch: 1.8003753083092826\n",
            "Training accuracy epoch: 0.17522321428571427\n",
            "Training epoch: 43\n",
            "Training loss per 100 training steps: 1.7479051351547241\n",
            "Training loss epoch: 1.8067904370171683\n",
            "Training accuracy epoch: 0.17354910714285715\n",
            "Training epoch: 44\n",
            "Training loss per 100 training steps: 1.8419835567474365\n",
            "Training loss epoch: 1.8116606303623743\n",
            "Training accuracy epoch: 0.15680803571428573\n",
            "Training epoch: 45\n",
            "Training loss per 100 training steps: 1.7539044618606567\n",
            "Training loss epoch: 1.7922330243246896\n",
            "Training accuracy epoch: 0.18638392857142858\n",
            "Training epoch: 46\n",
            "Training loss per 100 training steps: 1.8044166564941406\n",
            "Training loss epoch: 1.7936231579099382\n",
            "Training accuracy epoch: 0.18582589285714285\n",
            "Training epoch: 47\n",
            "Training loss per 100 training steps: 1.814613938331604\n",
            "Training loss epoch: 1.7987289088112968\n",
            "Training accuracy epoch: 0.19084821428571427\n",
            "Training epoch: 48\n",
            "Training loss per 100 training steps: 1.831143856048584\n",
            "Training loss epoch: 1.8112597635814123\n",
            "Training accuracy epoch: 0.16462053571428573\n",
            "Training epoch: 49\n",
            "Training loss per 100 training steps: 1.8558175563812256\n",
            "Training loss epoch: 1.7994709866387504\n",
            "Training accuracy epoch: 0.20368303571428573\n",
            "Training epoch: 50\n",
            "Training loss per 100 training steps: 1.7930535078048706\n",
            "Training loss epoch: 1.8019135338919503\n",
            "Training accuracy epoch: 0.17857142857142858\n",
            "Training epoch: 51\n",
            "Training loss per 100 training steps: 1.8145792484283447\n",
            "Training loss epoch: 1.7920904500143868\n",
            "Training accuracy epoch: 0.19196428571428573\n",
            "Training epoch: 52\n",
            "Training loss per 100 training steps: 1.7444883584976196\n",
            "Training loss epoch: 1.7877447605133057\n",
            "Training accuracy epoch: 0.18024553571428573\n",
            "Training epoch: 53\n",
            "Training loss per 100 training steps: 1.8030303716659546\n",
            "Training loss epoch: 1.7979072162083216\n",
            "Training accuracy epoch: 0.18582589285714285\n",
            "Training epoch: 54\n",
            "Training loss per 100 training steps: 1.7978423833847046\n",
            "Training loss epoch: 1.7883402109146118\n",
            "Training accuracy epoch: 0.18191964285714285\n",
            "Training epoch: 55\n",
            "Training loss per 100 training steps: 1.8164005279541016\n",
            "Training loss epoch: 1.7938358613422938\n",
            "Training accuracy epoch: 0.19308035714285715\n",
            "Training epoch: 56\n",
            "Training loss per 100 training steps: 1.799433946609497\n",
            "Training loss epoch: 1.7901036398751395\n",
            "Training accuracy epoch: 0.19084821428571427\n",
            "Training epoch: 57\n",
            "Training loss per 100 training steps: 1.7792925834655762\n",
            "Training loss epoch: 1.8049601316452026\n",
            "Training accuracy epoch: 0.17020089285714285\n",
            "Training epoch: 58\n",
            "Training loss per 100 training steps: 1.7634694576263428\n",
            "Training loss epoch: 1.804236922945295\n",
            "Training accuracy epoch: 0.17522321428571427\n",
            "Training epoch: 59\n",
            "Training loss per 100 training steps: 1.778336524963379\n",
            "Training loss epoch: 1.8172945465360368\n",
            "Training accuracy epoch: 0.16685267857142858\n",
            "Training epoch: 60\n",
            "Training loss per 100 training steps: 1.8072408437728882\n",
            "Training loss epoch: 1.7903495686394828\n",
            "Training accuracy epoch: 0.19698660714285715\n",
            "Training epoch: 61\n",
            "Training loss per 100 training steps: 1.776803970336914\n",
            "Training loss epoch: 1.7981370176587785\n",
            "Training accuracy epoch: 0.18024553571428573\n",
            "Training epoch: 62\n",
            "Training loss per 100 training steps: 1.9000823497772217\n",
            "Training loss epoch: 1.794149432863508\n",
            "Training accuracy epoch: 0.19140625\n",
            "Training epoch: 63\n",
            "Training loss per 100 training steps: 1.790600061416626\n",
            "Training loss epoch: 1.814048136983599\n",
            "Training accuracy epoch: 0.15680803571428573\n",
            "Training epoch: 64\n",
            "Training loss per 100 training steps: 1.7887296676635742\n",
            "Training loss epoch: 1.8175570113318307\n",
            "Training accuracy epoch: 0.17466517857142858\n",
            "Training epoch: 65\n",
            "Training loss per 100 training steps: 1.845754861831665\n",
            "Training loss epoch: 1.786042298589434\n",
            "Training accuracy epoch: 0.19140625\n",
            "Training epoch: 66\n",
            "Training loss per 100 training steps: 1.822535753250122\n",
            "Training loss epoch: 1.8174384321485246\n",
            "Training accuracy epoch: 0.16462053571428573\n",
            "Training epoch: 67\n",
            "Training loss per 100 training steps: 1.7974945306777954\n",
            "Training loss epoch: 1.8041151080812727\n",
            "Training accuracy epoch: 0.18303571428571427\n",
            "Training epoch: 68\n",
            "Training loss per 100 training steps: 1.7764328718185425\n",
            "Training loss epoch: 1.7862948349543981\n",
            "Training accuracy epoch: 0.19029017857142858\n",
            "Training epoch: 69\n",
            "Training loss per 100 training steps: 1.7769224643707275\n",
            "Training loss epoch: 1.774688686643328\n",
            "Training accuracy epoch: 0.21428571428571427\n",
            "Training epoch: 70\n",
            "Training loss per 100 training steps: 1.7532052993774414\n",
            "Training loss epoch: 1.793320826121739\n",
            "Training accuracy epoch: 0.19140625\n",
            "Training epoch: 71\n",
            "Training loss per 100 training steps: 1.801072597503662\n",
            "Training loss epoch: 1.800385253770011\n",
            "Training accuracy epoch: 0.17689732142857142\n",
            "Training epoch: 72\n",
            "Training loss per 100 training steps: 1.8113478422164917\n",
            "Training loss epoch: 1.801300082887922\n",
            "Training accuracy epoch: 0.17857142857142858\n",
            "Training epoch: 73\n",
            "Training loss per 100 training steps: 1.8074578046798706\n",
            "Training loss epoch: 1.788417169025966\n",
            "Training accuracy epoch: 0.19196428571428573\n",
            "Training epoch: 74\n",
            "Training loss per 100 training steps: 1.7689145803451538\n",
            "Training loss epoch: 1.7944883959633964\n",
            "Training accuracy epoch: 0.16964285714285715\n",
            "Training epoch: 75\n",
            "Training loss per 100 training steps: 1.8189717531204224\n",
            "Training loss epoch: 1.7944851432527815\n",
            "Training accuracy epoch: 0.18303571428571427\n",
            "Training epoch: 76\n",
            "Training loss per 100 training steps: 1.8010402917861938\n",
            "Training loss epoch: 1.797403131212507\n",
            "Training accuracy epoch: 0.18973214285714285\n",
            "Training epoch: 77\n",
            "Training loss per 100 training steps: 1.8673795461654663\n",
            "Training loss epoch: 1.7945144176483154\n",
            "Training accuracy epoch: 0.17745535714285715\n",
            "Training epoch: 78\n",
            "Training loss per 100 training steps: 1.8431313037872314\n",
            "Training loss epoch: 1.7947802203042167\n",
            "Training accuracy epoch: 0.18582589285714285\n",
            "Training epoch: 79\n",
            "Training loss per 100 training steps: 1.8270269632339478\n",
            "Training loss epoch: 1.8028582845415388\n",
            "Training accuracy epoch: 0.18247767857142858\n",
            "Training epoch: 80\n",
            "Training loss per 100 training steps: 1.7870935201644897\n",
            "Training loss epoch: 1.7934910910470145\n",
            "Training accuracy epoch: 0.17578125\n",
            "Training epoch: 81\n",
            "Training loss per 100 training steps: 1.8023613691329956\n",
            "Training loss epoch: 1.8130743162972587\n",
            "Training accuracy epoch: 0.16015625\n",
            "Training epoch: 82\n",
            "Training loss per 100 training steps: 1.8123482465744019\n",
            "Training loss epoch: 1.8064765759876795\n",
            "Training accuracy epoch: 0.18136160714285715\n",
            "Training epoch: 83\n",
            "Training loss per 100 training steps: 1.7691915035247803\n",
            "Training loss epoch: 1.8041388988494873\n",
            "Training accuracy epoch: 0.17075892857142858\n",
            "Training epoch: 84\n",
            "Training loss per 100 training steps: 1.783480167388916\n",
            "Training loss epoch: 1.784239445413862\n",
            "Training accuracy epoch: 0.19698660714285715\n",
            "Training epoch: 85\n",
            "Training loss per 100 training steps: 1.7933368682861328\n",
            "Training loss epoch: 1.803482038634164\n",
            "Training accuracy epoch: 0.17912946428571427\n",
            "Training epoch: 86\n",
            "Training loss per 100 training steps: 1.740059494972229\n",
            "Training loss epoch: 1.7820427758353097\n",
            "Training accuracy epoch: 0.19866071428571427\n",
            "Training epoch: 87\n",
            "Training loss per 100 training steps: 1.80869460105896\n",
            "Training loss epoch: 1.7988807814461845\n",
            "Training accuracy epoch: 0.1796875\n",
            "Training epoch: 88\n",
            "Training loss per 100 training steps: 1.7434556484222412\n",
            "Training loss epoch: 1.7772705725261144\n",
            "Training accuracy epoch: 0.21707589285714285\n",
            "Training epoch: 89\n",
            "Training loss per 100 training steps: 1.7480043172836304\n",
            "Training loss epoch: 1.794425129890442\n",
            "Training accuracy epoch: 0.19642857142857142\n",
            "Training epoch: 90\n",
            "Training loss per 100 training steps: 1.7860307693481445\n",
            "Training loss epoch: 1.79671311378479\n",
            "Training accuracy epoch: 0.18861607142857142\n",
            "Training epoch: 91\n",
            "Training loss per 100 training steps: 1.8368401527404785\n",
            "Training loss epoch: 1.8329341581889562\n",
            "Training accuracy epoch: 0.14732142857142858\n",
            "Training epoch: 92\n",
            "Training loss per 100 training steps: 1.7878961563110352\n",
            "Training loss epoch: 1.8013636725289481\n",
            "Training accuracy epoch: 0.16462053571428573\n",
            "Training epoch: 93\n",
            "Training loss per 100 training steps: 1.8620944023132324\n",
            "Training loss epoch: 1.7978696141924178\n",
            "Training accuracy epoch: 0.1796875\n",
            "Training epoch: 94\n",
            "Training loss per 100 training steps: 1.7953654527664185\n",
            "Training loss epoch: 1.779979978288923\n",
            "Training accuracy epoch: 0.20926339285714285\n",
            "Training epoch: 95\n",
            "Training loss per 100 training steps: 1.7364329099655151\n",
            "Training loss epoch: 1.791736670902797\n",
            "Training accuracy epoch: 0.18638392857142858\n",
            "Training epoch: 96\n",
            "Training loss per 100 training steps: 1.7876112461090088\n",
            "Training loss epoch: 1.8125284229006087\n",
            "Training accuracy epoch: 0.17578125\n",
            "Training epoch: 97\n",
            "Training loss per 100 training steps: 1.753151297569275\n",
            "Training loss epoch: 1.8085200956889562\n",
            "Training accuracy epoch: 0.15959821428571427\n",
            "Training epoch: 98\n",
            "Training loss per 100 training steps: 1.8017715215682983\n",
            "Training loss epoch: 1.8171371562140328\n",
            "Training accuracy epoch: 0.16294642857142858\n",
            "Training epoch: 99\n",
            "Training loss per 100 training steps: 1.7644579410552979\n",
            "Training loss epoch: 1.7968013797487532\n",
            "Training accuracy epoch: 0.18080357142857142\n",
            "Training epoch: 100\n",
            "Training loss per 100 training steps: 1.7532521486282349\n",
            "Training loss epoch: 1.794881990977696\n",
            "Training accuracy epoch: 0.19642857142857142\n",
            "Training epoch: 101\n",
            "Training loss per 100 training steps: 1.8596850633621216\n",
            "Training loss epoch: 1.8001811163766044\n",
            "Training accuracy epoch: 0.17020089285714285\n",
            "Training epoch: 102\n",
            "Training loss per 100 training steps: 1.766770362854004\n",
            "Training loss epoch: 1.7877830948148454\n",
            "Training accuracy epoch: 0.18638392857142858\n",
            "Training epoch: 103\n",
            "Training loss per 100 training steps: 1.8005965948104858\n",
            "Training loss epoch: 1.7935168743133545\n",
            "Training accuracy epoch: 0.19196428571428573\n",
            "Training epoch: 104\n",
            "Training loss per 100 training steps: 1.860715627670288\n",
            "Training loss epoch: 1.7996840987886702\n",
            "Training accuracy epoch: 0.17912946428571427\n",
            "Training epoch: 105\n",
            "Training loss per 100 training steps: 1.7839988470077515\n",
            "Training loss epoch: 1.7926317623683385\n",
            "Training accuracy epoch: 0.171875\n",
            "Training epoch: 106\n",
            "Training loss per 100 training steps: 1.7686378955841064\n",
            "Training loss epoch: 1.7823114054543632\n",
            "Training accuracy epoch: 0.20535714285714285\n",
            "Training epoch: 107\n",
            "Training loss per 100 training steps: 1.7942711114883423\n",
            "Training loss epoch: 1.7930550915854317\n",
            "Training accuracy epoch: 0.18638392857142858\n",
            "Training epoch: 108\n",
            "Training loss per 100 training steps: 1.8452608585357666\n",
            "Training loss epoch: 1.8093299525124686\n",
            "Training accuracy epoch: 0.15904017857142858\n",
            "Training epoch: 109\n",
            "Training loss per 100 training steps: 1.8153777122497559\n",
            "Training loss epoch: 1.7961081777300154\n",
            "Training accuracy epoch: 0.19084821428571427\n",
            "Training epoch: 110\n",
            "Training loss per 100 training steps: 1.9062278270721436\n",
            "Training loss epoch: 1.7890962191990443\n",
            "Training accuracy epoch: 0.20703125\n",
            "Training epoch: 111\n",
            "Training loss per 100 training steps: 1.8250319957733154\n",
            "Training loss epoch: 1.8045465775898524\n",
            "Training accuracy epoch: 0.17131696428571427\n",
            "Training epoch: 112\n",
            "Training loss per 100 training steps: 1.79214608669281\n",
            "Training loss epoch: 1.8057449885777064\n",
            "Training accuracy epoch: 0.171875\n",
            "Training epoch: 113\n",
            "Training loss per 100 training steps: 1.8127615451812744\n",
            "Training loss epoch: 1.7784207378114973\n",
            "Training accuracy epoch: 0.20145089285714285\n",
            "Training epoch: 114\n",
            "Training loss per 100 training steps: 1.7957130670547485\n",
            "Training loss epoch: 1.7821475097111292\n",
            "Training accuracy epoch: 0.19921875\n",
            "Training epoch: 115\n",
            "Training loss per 100 training steps: 1.8691798448562622\n",
            "Training loss epoch: 1.7991933141435896\n",
            "Training accuracy epoch: 0.18080357142857142\n",
            "Training epoch: 116\n",
            "Training loss per 100 training steps: 1.8820791244506836\n",
            "Training loss epoch: 1.8132708072662354\n",
            "Training accuracy epoch: 0.18470982142857142\n",
            "Training epoch: 117\n",
            "Training loss per 100 training steps: 1.8109208345413208\n",
            "Training loss epoch: 1.786368659564427\n",
            "Training accuracy epoch: 0.18805803571428573\n",
            "Training epoch: 118\n",
            "Training loss per 100 training steps: 1.8021527528762817\n",
            "Training loss epoch: 1.7954335723604475\n",
            "Training accuracy epoch: 0.18470982142857142\n",
            "Training epoch: 119\n",
            "Training loss per 100 training steps: 1.7887300252914429\n",
            "Training loss epoch: 1.7847345556531633\n",
            "Training accuracy epoch: 0.20591517857142858\n",
            "Training epoch: 120\n",
            "Training loss per 100 training steps: 1.791014552116394\n",
            "Training loss epoch: 1.7938809565135412\n",
            "Training accuracy epoch: 0.19308035714285715\n",
            "Training epoch: 121\n",
            "Training loss per 100 training steps: 1.8307671546936035\n",
            "Training loss epoch: 1.7862406628472465\n",
            "Training accuracy epoch: 0.19810267857142858\n",
            "Training epoch: 122\n",
            "Training loss per 100 training steps: 1.7838482856750488\n",
            "Training loss epoch: 1.7844278131212508\n",
            "Training accuracy epoch: 0.20424107142857142\n",
            "Training epoch: 123\n",
            "Training loss per 100 training steps: 1.7619726657867432\n",
            "Training loss epoch: 1.7844573940549577\n",
            "Training accuracy epoch: 0.21037946428571427\n",
            "Training epoch: 124\n",
            "Training loss per 100 training steps: 1.7426433563232422\n",
            "Training loss epoch: 1.79649019241333\n",
            "Training accuracy epoch: 0.19475446428571427\n",
            "Training epoch: 125\n",
            "Training loss per 100 training steps: 1.7447553873062134\n",
            "Training loss epoch: 1.7982477801186698\n",
            "Training accuracy epoch: 0.18024553571428573\n",
            "Training epoch: 126\n",
            "Training loss per 100 training steps: 1.754867672920227\n",
            "Training loss epoch: 1.7761725527899606\n",
            "Training accuracy epoch: 0.20591517857142858\n",
            "Training epoch: 127\n",
            "Training loss per 100 training steps: 1.8859330415725708\n",
            "Training loss epoch: 1.7896572521754675\n",
            "Training accuracy epoch: 0.18359375\n",
            "Training epoch: 128\n",
            "Training loss per 100 training steps: 1.7741081714630127\n",
            "Training loss epoch: 1.7931998797825404\n",
            "Training accuracy epoch: 0.19084821428571427\n",
            "Training epoch: 129\n",
            "Training loss per 100 training steps: 1.7867792844772339\n",
            "Training loss epoch: 1.7791293859481812\n",
            "Training accuracy epoch: 0.20591517857142858\n",
            "Training epoch: 130\n",
            "Training loss per 100 training steps: 1.8279616832733154\n",
            "Training loss epoch: 1.7681820562907629\n",
            "Training accuracy epoch: 0.23325892857142858\n",
            "Training epoch: 131\n",
            "Training loss per 100 training steps: 1.7845181226730347\n",
            "Training loss epoch: 1.8032570736748832\n",
            "Training accuracy epoch: 0.1640625\n",
            "Training epoch: 132\n",
            "Training loss per 100 training steps: 1.8142017126083374\n",
            "Training loss epoch: 1.780436941555568\n",
            "Training accuracy epoch: 0.20479910714285715\n",
            "Training epoch: 133\n",
            "Training loss per 100 training steps: 1.8089840412139893\n",
            "Training loss epoch: 1.7951883247920446\n",
            "Training accuracy epoch: 0.1953125\n",
            "Training epoch: 134\n",
            "Training loss per 100 training steps: 1.7671502828598022\n",
            "Training loss epoch: 1.8066238164901733\n",
            "Training accuracy epoch: 0.17020089285714285\n",
            "Training epoch: 135\n",
            "Training loss per 100 training steps: 1.758604884147644\n",
            "Training loss epoch: 1.8002790893827165\n",
            "Training accuracy epoch: 0.17075892857142858\n",
            "Training epoch: 136\n",
            "Training loss per 100 training steps: 1.864100694656372\n",
            "Training loss epoch: 1.7846855095454626\n",
            "Training accuracy epoch: 0.20368303571428573\n",
            "Training epoch: 137\n",
            "Training loss per 100 training steps: 1.8327325582504272\n",
            "Training loss epoch: 1.8011925561087472\n",
            "Training accuracy epoch: 0.1796875\n",
            "Training epoch: 138\n",
            "Training loss per 100 training steps: 1.7801650762557983\n",
            "Training loss epoch: 1.7899964877537318\n",
            "Training accuracy epoch: 0.19475446428571427\n",
            "Training epoch: 139\n",
            "Training loss per 100 training steps: 1.7869855165481567\n",
            "Training loss epoch: 1.7902261699948991\n",
            "Training accuracy epoch: 0.18917410714285715\n",
            "Training epoch: 140\n",
            "Training loss per 100 training steps: 1.7524223327636719\n",
            "Training loss epoch: 1.8100426197052002\n",
            "Training accuracy epoch: 0.16294642857142858\n",
            "Training epoch: 141\n",
            "Training loss per 100 training steps: 1.78657066822052\n",
            "Training loss epoch: 1.7917665072849818\n",
            "Training accuracy epoch: 0.19977678571428573\n",
            "Training epoch: 142\n",
            "Training loss per 100 training steps: 1.7928383350372314\n",
            "Training loss epoch: 1.7962821551731654\n",
            "Training accuracy epoch: 0.1796875\n",
            "Training epoch: 143\n",
            "Training loss per 100 training steps: 1.7502413988113403\n",
            "Training loss epoch: 1.7998797723225184\n",
            "Training accuracy epoch: 0.1875\n",
            "Training epoch: 144\n",
            "Training loss per 100 training steps: 1.8423517942428589\n",
            "Training loss epoch: 1.794905424118042\n",
            "Training accuracy epoch: 0.17857142857142858\n",
            "Training epoch: 145\n",
            "Training loss per 100 training steps: 1.7628071308135986\n",
            "Training loss epoch: 1.800334402493068\n",
            "Training accuracy epoch: 0.17912946428571427\n",
            "Training epoch: 146\n",
            "Training loss per 100 training steps: 1.7903951406478882\n",
            "Training loss epoch: 1.8071943862097604\n",
            "Training accuracy epoch: 0.16127232142857142\n",
            "Training epoch: 147\n",
            "Training loss per 100 training steps: 1.7965279817581177\n",
            "Training loss epoch: 1.8282809938703264\n",
            "Training accuracy epoch: 0.14955357142857142\n",
            "Training epoch: 148\n",
            "Training loss per 100 training steps: 1.7541804313659668\n",
            "Training loss epoch: 1.797383393560137\n",
            "Training accuracy epoch: 0.18136160714285715\n",
            "Training epoch: 149\n",
            "Training loss per 100 training steps: 1.8585156202316284\n",
            "Training loss epoch: 1.7941269023077828\n",
            "Training accuracy epoch: 0.18917410714285715\n",
            "Training epoch: 150\n",
            "Training loss per 100 training steps: 1.822303056716919\n",
            "Training loss epoch: 1.8122732469013758\n",
            "Training accuracy epoch: 0.14955357142857142\n",
            "Training epoch: 151\n",
            "Training loss per 100 training steps: 1.818206548690796\n",
            "Training loss epoch: 1.8068309000560216\n",
            "Training accuracy epoch: 0.16573660714285715\n",
            "Training epoch: 152\n",
            "Training loss per 100 training steps: 1.7712318897247314\n",
            "Training loss epoch: 1.8223920890263148\n",
            "Training accuracy epoch: 0.14732142857142858\n",
            "Training epoch: 153\n",
            "Training loss per 100 training steps: 1.7932257652282715\n",
            "Training loss epoch: 1.7987124238695418\n",
            "Training accuracy epoch: 0.18024553571428573\n",
            "Training epoch: 154\n",
            "Training loss per 100 training steps: 1.7606929540634155\n",
            "Training loss epoch: 1.7964015517915999\n",
            "Training accuracy epoch: 0.19810267857142858\n",
            "Training epoch: 155\n",
            "Training loss per 100 training steps: 1.7899142503738403\n",
            "Training loss epoch: 1.8057827949523926\n",
            "Training accuracy epoch: 0.1640625\n",
            "Training epoch: 156\n",
            "Training loss per 100 training steps: 1.7712013721466064\n",
            "Training loss epoch: 1.8108800309044975\n",
            "Training accuracy epoch: 0.16462053571428573\n",
            "Training epoch: 157\n",
            "Training loss per 100 training steps: 1.78127121925354\n",
            "Training loss epoch: 1.8002979244504655\n",
            "Training accuracy epoch: 0.16741071428571427\n",
            "Training epoch: 158\n",
            "Training loss per 100 training steps: 1.8195126056671143\n",
            "Training loss epoch: 1.7946790286472865\n",
            "Training accuracy epoch: 0.17075892857142858\n",
            "Training epoch: 159\n",
            "Training loss per 100 training steps: 1.7784909009933472\n",
            "Training loss epoch: 1.7942519698824202\n",
            "Training accuracy epoch: 0.19196428571428573\n",
            "Training epoch: 160\n",
            "Training loss per 100 training steps: 1.8395949602127075\n",
            "Training loss epoch: 1.808617012841361\n",
            "Training accuracy epoch: 0.17689732142857142\n",
            "Training epoch: 161\n",
            "Training loss per 100 training steps: 1.7637939453125\n",
            "Training loss epoch: 1.8005284752164568\n",
            "Training accuracy epoch: 0.18136160714285715\n",
            "Training epoch: 162\n",
            "Training loss per 100 training steps: 1.8029499053955078\n",
            "Training loss epoch: 1.813879098211016\n",
            "Training accuracy epoch: 0.17466517857142858\n",
            "Training epoch: 163\n",
            "Training loss per 100 training steps: 1.779525876045227\n",
            "Training loss epoch: 1.7892733301435197\n",
            "Training accuracy epoch: 0.19866071428571427\n",
            "Training epoch: 164\n",
            "Training loss per 100 training steps: 1.847641944885254\n",
            "Training loss epoch: 1.7907626628875732\n",
            "Training accuracy epoch: 0.18638392857142858\n",
            "Training epoch: 165\n",
            "Training loss per 100 training steps: 1.81617271900177\n",
            "Training loss epoch: 1.790915880884443\n",
            "Training accuracy epoch: 0.19587053571428573\n",
            "Training epoch: 166\n",
            "Training loss per 100 training steps: 1.8245530128479004\n",
            "Training loss epoch: 1.8144869804382324\n",
            "Training accuracy epoch: 0.16183035714285715\n",
            "Training epoch: 167\n",
            "Training loss per 100 training steps: 1.7939221858978271\n",
            "Training loss epoch: 1.7941970995494299\n",
            "Training accuracy epoch: 0.17522321428571427\n",
            "Training epoch: 168\n",
            "Training loss per 100 training steps: 1.827210545539856\n",
            "Training loss epoch: 1.788095440183367\n",
            "Training accuracy epoch: 0.19140625\n",
            "Training epoch: 169\n",
            "Training loss per 100 training steps: 1.8367149829864502\n",
            "Training loss epoch: 1.7936526877539498\n",
            "Training accuracy epoch: 0.17410714285714285\n",
            "Training epoch: 170\n",
            "Training loss per 100 training steps: 1.7657299041748047\n",
            "Training loss epoch: 1.7919167961393083\n",
            "Training accuracy epoch: 0.20535714285714285\n",
            "Training epoch: 171\n",
            "Training loss per 100 training steps: 1.784164309501648\n",
            "Training loss epoch: 1.7952858039311\n",
            "Training accuracy epoch: 0.19029017857142858\n",
            "Training epoch: 172\n",
            "Training loss per 100 training steps: 1.7963738441467285\n",
            "Training loss epoch: 1.8095993484769548\n",
            "Training accuracy epoch: 0.15513392857142858\n",
            "Training epoch: 173\n",
            "Training loss per 100 training steps: 1.8020567893981934\n",
            "Training loss epoch: 1.804024577140808\n",
            "Training accuracy epoch: 0.171875\n",
            "Training epoch: 174\n",
            "Training loss per 100 training steps: 1.7897449731826782\n",
            "Training loss epoch: 1.7960767575672694\n",
            "Training accuracy epoch: 0.17912946428571427\n",
            "Training epoch: 175\n",
            "Training loss per 100 training steps: 1.7681629657745361\n",
            "Training loss epoch: 1.8057217597961426\n",
            "Training accuracy epoch: 0.16238839285714285\n",
            "Training epoch: 176\n",
            "Training loss per 100 training steps: 1.7509526014328003\n",
            "Training loss epoch: 1.7869267293385096\n",
            "Training accuracy epoch: 0.19084821428571427\n",
            "Training epoch: 177\n",
            "Training loss per 100 training steps: 1.7598788738250732\n",
            "Training loss epoch: 1.7955509764807565\n",
            "Training accuracy epoch: 0.19140625\n",
            "Training epoch: 178\n",
            "Training loss per 100 training steps: 1.7913275957107544\n",
            "Training loss epoch: 1.8026108401162284\n",
            "Training accuracy epoch: 0.17633928571428573\n",
            "Training epoch: 179\n",
            "Training loss per 100 training steps: 1.8230215311050415\n",
            "Training loss epoch: 1.812686460358756\n",
            "Training accuracy epoch: 0.15848214285714285\n",
            "Training epoch: 180\n",
            "Training loss per 100 training steps: 1.7233977317810059\n",
            "Training loss epoch: 1.7825956685202462\n",
            "Training accuracy epoch: 0.20089285714285715\n",
            "Training epoch: 181\n",
            "Training loss per 100 training steps: 1.7448633909225464\n",
            "Training loss epoch: 1.8040557418550764\n",
            "Training accuracy epoch: 0.17131696428571427\n",
            "Training epoch: 182\n",
            "Training loss per 100 training steps: 1.776353120803833\n",
            "Training loss epoch: 1.8220281771251134\n",
            "Training accuracy epoch: 0.13895089285714285\n",
            "Training epoch: 183\n",
            "Training loss per 100 training steps: 1.8623950481414795\n",
            "Training loss epoch: 1.7971046481813704\n",
            "Training accuracy epoch: 0.19029017857142858\n",
            "Training epoch: 184\n",
            "Training loss per 100 training steps: 1.7817778587341309\n",
            "Training loss epoch: 1.7794197457177299\n",
            "Training accuracy epoch: 0.203125\n",
            "Training epoch: 185\n",
            "Training loss per 100 training steps: 1.7936636209487915\n",
            "Training loss epoch: 1.7888570172446114\n",
            "Training accuracy epoch: 0.18917410714285715\n",
            "Training epoch: 186\n",
            "Training loss per 100 training steps: 1.8591710329055786\n",
            "Training loss epoch: 1.8085918256214686\n",
            "Training accuracy epoch: 0.16238839285714285\n",
            "Training epoch: 187\n",
            "Training loss per 100 training steps: 1.769552230834961\n",
            "Training loss epoch: 1.791878581047058\n",
            "Training accuracy epoch: 0.18917410714285715\n",
            "Training epoch: 188\n",
            "Training loss per 100 training steps: 1.75096595287323\n",
            "Training loss epoch: 1.7722864151000977\n",
            "Training accuracy epoch: 0.22042410714285715\n",
            "Training epoch: 189\n",
            "Training loss per 100 training steps: 1.893951177597046\n",
            "Training loss epoch: 1.7918166433061873\n",
            "Training accuracy epoch: 0.18805803571428573\n",
            "Training epoch: 190\n",
            "Training loss per 100 training steps: 1.8493945598602295\n",
            "Training loss epoch: 1.800678985459464\n",
            "Training accuracy epoch: 0.18191964285714285\n",
            "Training epoch: 191\n",
            "Training loss per 100 training steps: 1.806694746017456\n",
            "Training loss epoch: 1.7939833913530623\n",
            "Training accuracy epoch: 0.19308035714285715\n",
            "Training epoch: 192\n",
            "Training loss per 100 training steps: 1.7679082155227661\n",
            "Training loss epoch: 1.7898237364632743\n",
            "Training accuracy epoch: 0.18917410714285715\n",
            "Training epoch: 193\n",
            "Training loss per 100 training steps: 1.8494882583618164\n",
            "Training loss epoch: 1.8005188022341048\n",
            "Training accuracy epoch: 0.16183035714285715\n",
            "Training epoch: 194\n",
            "Training loss per 100 training steps: 1.835329294204712\n",
            "Training loss epoch: 1.7890856606619698\n",
            "Training accuracy epoch: 0.18582589285714285\n",
            "Training epoch: 195\n",
            "Training loss per 100 training steps: 1.789015531539917\n",
            "Training loss epoch: 1.7781516994748796\n",
            "Training accuracy epoch: 0.20089285714285715\n",
            "Training epoch: 196\n",
            "Training loss per 100 training steps: 1.7557395696640015\n",
            "Training loss epoch: 1.7934159210750036\n",
            "Training accuracy epoch: 0.19308035714285715\n",
            "Training epoch: 197\n",
            "Training loss per 100 training steps: 1.7839759588241577\n",
            "Training loss epoch: 1.793406367301941\n",
            "Training accuracy epoch: 0.17020089285714285\n",
            "Training epoch: 198\n",
            "Training loss per 100 training steps: 1.879189372062683\n",
            "Training loss epoch: 1.7965439217431205\n",
            "Training accuracy epoch: 0.18191964285714285\n",
            "Training epoch: 199\n",
            "Training loss per 100 training steps: 1.7826508283615112\n",
            "Training loss epoch: 1.7981154407773698\n",
            "Training accuracy epoch: 0.18080357142857142\n",
            "Training epoch: 200\n",
            "Training loss per 100 training steps: 1.8745988607406616\n",
            "Training loss epoch: 1.800019349370684\n",
            "Training accuracy epoch: 0.17745535714285715\n",
            "Training epoch: 201\n",
            "Training loss per 100 training steps: 1.8401461839675903\n",
            "Training loss epoch: 1.8033348492213659\n",
            "Training accuracy epoch: 0.16573660714285715\n",
            "Training epoch: 202\n",
            "Training loss per 100 training steps: 1.8059492111206055\n",
            "Training loss epoch: 1.7974729027066911\n",
            "Training accuracy epoch: 0.18359375\n",
            "Training epoch: 203\n",
            "Training loss per 100 training steps: 1.815109372138977\n",
            "Training loss epoch: 1.7838090998785836\n",
            "Training accuracy epoch: 0.18359375\n",
            "Training epoch: 204\n",
            "Training loss per 100 training steps: 1.7959635257720947\n",
            "Training loss epoch: 1.7972071511404855\n",
            "Training accuracy epoch: 0.16796875\n",
            "Training epoch: 205\n",
            "Training loss per 100 training steps: 1.7432790994644165\n",
            "Training loss epoch: 1.8030646187918526\n",
            "Training accuracy epoch: 0.16852678571428573\n",
            "Training epoch: 206\n",
            "Training loss per 100 training steps: 1.758886694908142\n",
            "Training loss epoch: 1.790609495980399\n",
            "Training accuracy epoch: 0.19196428571428573\n",
            "Training epoch: 207\n",
            "Training loss per 100 training steps: 1.7821394205093384\n",
            "Training loss epoch: 1.780794313975743\n",
            "Training accuracy epoch: 0.19196428571428573\n",
            "Training epoch: 208\n",
            "Training loss per 100 training steps: 1.7714059352874756\n",
            "Training loss epoch: 1.787890008517674\n",
            "Training accuracy epoch: 0.19029017857142858\n",
            "Training epoch: 209\n",
            "Training loss per 100 training steps: 1.7819688320159912\n",
            "Training loss epoch: 1.7839331115995134\n",
            "Training accuracy epoch: 0.18582589285714285\n",
            "Training epoch: 210\n",
            "Training loss per 100 training steps: 1.7388412952423096\n",
            "Training loss epoch: 1.8097298315593175\n",
            "Training accuracy epoch: 0.17299107142857142\n",
            "Training epoch: 211\n",
            "Training loss per 100 training steps: 1.780840277671814\n",
            "Training loss epoch: 1.7964208807264055\n",
            "Training accuracy epoch: 0.18805803571428573\n",
            "Training epoch: 212\n",
            "Training loss per 100 training steps: 1.8158243894577026\n",
            "Training loss epoch: 1.8030789239065987\n",
            "Training accuracy epoch: 0.18080357142857142\n",
            "Training epoch: 213\n",
            "Training loss per 100 training steps: 1.7519816160202026\n",
            "Training loss epoch: 1.7958545684814453\n",
            "Training accuracy epoch: 0.19196428571428573\n",
            "Training epoch: 214\n",
            "Training loss per 100 training steps: 1.7954800128936768\n",
            "Training loss epoch: 1.8188413040978568\n",
            "Training accuracy epoch: 0.15736607142857142\n",
            "Training epoch: 215\n",
            "Training loss per 100 training steps: 1.76272714138031\n",
            "Training loss epoch: 1.819037709917341\n",
            "Training accuracy epoch: 0.16183035714285715\n",
            "Training epoch: 216\n",
            "Training loss per 100 training steps: 1.7557411193847656\n",
            "Training loss epoch: 1.8012850625174386\n",
            "Training accuracy epoch: 0.18526785714285715\n",
            "Training epoch: 217\n",
            "Training loss per 100 training steps: 1.8490941524505615\n",
            "Training loss epoch: 1.7896257638931274\n",
            "Training accuracy epoch: 0.1953125\n",
            "Training epoch: 218\n",
            "Training loss per 100 training steps: 1.7970452308654785\n",
            "Training loss epoch: 1.7937795945576258\n",
            "Training accuracy epoch: 0.18303571428571427\n",
            "Training epoch: 219\n",
            "Training loss per 100 training steps: 1.8551758527755737\n",
            "Training loss epoch: 1.7801228761672974\n",
            "Training accuracy epoch: 0.19921875\n",
            "Training epoch: 220\n",
            "Training loss per 100 training steps: 1.7706190347671509\n",
            "Training loss epoch: 1.7977072851998466\n",
            "Training accuracy epoch: 0.18470982142857142\n",
            "Training epoch: 221\n",
            "Training loss per 100 training steps: 1.8114335536956787\n",
            "Training loss epoch: 1.8016385691506522\n",
            "Training accuracy epoch: 0.16908482142857142\n",
            "Training epoch: 222\n",
            "Training loss per 100 training steps: 1.74949312210083\n",
            "Training loss epoch: 1.8004440069198608\n",
            "Training accuracy epoch: 0.19029017857142858\n",
            "Training epoch: 223\n",
            "Training loss per 100 training steps: 1.777173399925232\n",
            "Training loss epoch: 1.814678396497454\n",
            "Training accuracy epoch: 0.16852678571428573\n",
            "Training epoch: 224\n",
            "Training loss per 100 training steps: 1.8878675699234009\n",
            "Training loss epoch: 1.8166004930223738\n",
            "Training accuracy epoch: 0.16517857142857142\n",
            "Training epoch: 225\n",
            "Training loss per 100 training steps: 1.802100419998169\n",
            "Training loss epoch: 1.7981774125780379\n",
            "Training accuracy epoch: 0.18080357142857142\n",
            "Training epoch: 226\n",
            "Training loss per 100 training steps: 1.809916377067566\n",
            "Training loss epoch: 1.8204915693828039\n",
            "Training accuracy epoch: 0.15569196428571427\n",
            "Training epoch: 227\n",
            "Training loss per 100 training steps: 1.767849326133728\n",
            "Training loss epoch: 1.7873494625091553\n",
            "Training accuracy epoch: 0.19252232142857142\n",
            "Training epoch: 228\n",
            "Training loss per 100 training steps: 1.7550714015960693\n",
            "Training loss epoch: 1.7934815543038505\n",
            "Training accuracy epoch: 0.18415178571428573\n",
            "Training epoch: 229\n",
            "Training loss per 100 training steps: 1.8882238864898682\n",
            "Training loss epoch: 1.7971158538545882\n",
            "Training accuracy epoch: 0.18415178571428573\n",
            "Training epoch: 230\n",
            "Training loss per 100 training steps: 1.7649916410446167\n",
            "Training loss epoch: 1.7914990527289254\n",
            "Training accuracy epoch: 0.18526785714285715\n",
            "Training epoch: 231\n",
            "Training loss per 100 training steps: 1.811048150062561\n",
            "Training loss epoch: 1.7845288685389928\n",
            "Training accuracy epoch: 0.20479910714285715\n",
            "Training epoch: 232\n",
            "Training loss per 100 training steps: 1.763807773590088\n",
            "Training loss epoch: 1.8009125334875924\n",
            "Training accuracy epoch: 0.17633928571428573\n",
            "Training epoch: 233\n",
            "Training loss per 100 training steps: 1.862160325050354\n",
            "Training loss epoch: 1.7966056891850062\n",
            "Training accuracy epoch: 0.18805803571428573\n",
            "Training epoch: 234\n",
            "Training loss per 100 training steps: 1.7906439304351807\n",
            "Training loss epoch: 1.7970375163214547\n",
            "Training accuracy epoch: 0.18861607142857142\n",
            "Training epoch: 235\n",
            "Training loss per 100 training steps: 1.8797802925109863\n",
            "Training loss epoch: 1.8036387137004308\n",
            "Training accuracy epoch: 0.18359375\n",
            "Training epoch: 236\n",
            "Training loss per 100 training steps: 1.866466760635376\n",
            "Training loss epoch: 1.8113816976547241\n",
            "Training accuracy epoch: 0.16350446428571427\n",
            "Training epoch: 237\n",
            "Training loss per 100 training steps: 1.8056334257125854\n",
            "Training loss epoch: 1.8120147671018327\n",
            "Training accuracy epoch: 0.171875\n",
            "Training epoch: 238\n",
            "Training loss per 100 training steps: 1.7693798542022705\n",
            "Training loss epoch: 1.7994934490748815\n",
            "Training accuracy epoch: 0.16852678571428573\n",
            "Training epoch: 239\n",
            "Training loss per 100 training steps: 1.7762861251831055\n",
            "Training loss epoch: 1.8107024431228638\n",
            "Training accuracy epoch: 0.15234375\n",
            "Training epoch: 240\n",
            "Training loss per 100 training steps: 1.8690704107284546\n",
            "Training loss epoch: 1.8049425738198417\n",
            "Training accuracy epoch: 0.17522321428571427\n",
            "Training epoch: 241\n",
            "Training loss per 100 training steps: 1.8428452014923096\n",
            "Training loss epoch: 1.795850362096514\n",
            "Training accuracy epoch: 0.19810267857142858\n",
            "Training epoch: 242\n",
            "Training loss per 100 training steps: 1.757736325263977\n",
            "Training loss epoch: 1.7959400585719518\n",
            "Training accuracy epoch: 0.18582589285714285\n",
            "Training epoch: 243\n",
            "Training loss per 100 training steps: 1.8660598993301392\n",
            "Training loss epoch: 1.8122795990535192\n",
            "Training accuracy epoch: 0.18359375\n",
            "Training epoch: 244\n",
            "Training loss per 100 training steps: 1.8084808588027954\n",
            "Training loss epoch: 1.8262534482138497\n",
            "Training accuracy epoch: 0.14564732142857142\n",
            "Training epoch: 245\n",
            "Training loss per 100 training steps: 1.8119562864303589\n",
            "Training loss epoch: 1.7887096405029297\n",
            "Training accuracy epoch: 0.18582589285714285\n",
            "Training epoch: 246\n",
            "Training loss per 100 training steps: 1.8146708011627197\n",
            "Training loss epoch: 1.7981470482689994\n",
            "Training accuracy epoch: 0.17075892857142858\n",
            "Training epoch: 247\n",
            "Training loss per 100 training steps: 1.8234554529190063\n",
            "Training loss epoch: 1.8039134570530482\n",
            "Training accuracy epoch: 0.17075892857142858\n",
            "Training epoch: 248\n",
            "Training loss per 100 training steps: 1.77083158493042\n",
            "Training loss epoch: 1.8051492827279227\n",
            "Training accuracy epoch: 0.17466517857142858\n",
            "Training epoch: 249\n",
            "Training loss per 100 training steps: 1.7629425525665283\n",
            "Training loss epoch: 1.789098586354937\n",
            "Training accuracy epoch: 0.1953125\n",
            "Training epoch: 250\n",
            "Training loss per 100 training steps: 1.7731086015701294\n",
            "Training loss epoch: 1.7911436898367745\n",
            "Training accuracy epoch: 0.18973214285714285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def valid(model, testing_loader):\n",
        "    # put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_examples, nb_eval_steps = 0, 0\n",
        "    eval_preds, eval_labels = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, batch in enumerate(testing_loader):\n",
        "\n",
        "            ids = batch['ids'].to(device, dtype = torch.long)\n",
        "            mask = batch['mask'].to(device, dtype = torch.long)\n",
        "            targets = batch['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
        "            loss, eval_logits = outputs.loss, outputs.logits\n",
        "\n",
        "            eval_loss += loss.item()\n",
        "\n",
        "            nb_eval_steps += 1\n",
        "            nb_eval_examples += targets.size(0)\n",
        "\n",
        "            if idx % 100==0:\n",
        "                loss_step = eval_loss/nb_eval_steps\n",
        "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
        "\n",
        "            # compute evaluation accuracy\n",
        "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
        "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
        "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
        "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
        "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
        "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
        "\n",
        "            eval_labels.extend(targets)\n",
        "            eval_preds.extend(predictions)\n",
        "\n",
        "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
        "            eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    #print(eval_labels)\n",
        "    #print(eval_preds)\n",
        "\n",
        "    labels = [id2label[id.item()] for id in eval_labels]\n",
        "    predictions = [id2label[id.item()] for id in eval_preds]\n",
        "\n",
        "    #print(labels)\n",
        "    #print(predictions)\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
        "    print(f\"Validation Loss: {eval_loss}\")\n",
        "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
        "\n",
        "    return labels, predictions"
      ],
      "metadata": {
        "id": "hekXdHsmPGUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels, predictions = valid(model, testing_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPJBDDq8PGYU",
        "outputId": "301cd0f7-6eae-47a2-c8ea-e175d82433c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss per 100 evaluation steps: 1.9051517248153687\n",
            "Validation Loss: 1.9051517248153687\n",
            "Validation Accuracy: 0.078125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import classification_report\n",
        "\n",
        "print(classification_report([labels], [predictions]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78O013RNDIGq",
        "outputId": "1cd74a4f-bc54-49aa-ada4-42d3d9293433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         age       0.15      0.57      0.24         7\n",
            "        name       0.00      0.00      0.00         7\n",
            "    position       0.07      0.22      0.10         9\n",
            "\n",
            "   micro avg       0.06      0.26      0.10        23\n",
            "   macro avg       0.07      0.26      0.11        23\n",
            "weighted avg       0.07      0.26      0.11        23\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"\"\"\n",
        "name: dayong sun    age: 43    position: president, chief executive officer, treasurer, secretary and director    each director serves\n",
        "until the next annual meeting of shareholders and until his/her successor shall have been elected and qualified.\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
        "\n",
        "# move to gpu\n",
        "ids = inputs[\"input_ids\"].to(device)\n",
        "mask = inputs[\"attention_mask\"].to(device)\n",
        "# forward pass\n",
        "outputs = model(ids, mask)\n",
        "logits = outputs[0]\n",
        "\n",
        "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
        "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
        "\n",
        "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
        "token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
        "wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
        "\n",
        "word_level_predictions = []\n",
        "for pair in wp_preds:\n",
        "  if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
        "    # skip prediction\n",
        "    continue\n",
        "  else:\n",
        "    word_level_predictions.append(pair[1])\n",
        "\n",
        "# we join tokens, if they are not special ones\n",
        "str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n",
        "print(str_rep)\n",
        "print(word_level_predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjKiIu8cDIJy",
        "outputId": "236b836d-18f2-40df-fb31-e5733af53d3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name : dayong sun age : 43 position : president , chief executive officer , treasurer , secretary and director each director serves until the next annual meeting of shareholders and until his / her successor shall have been elected and qualified .\n",
            "['B-age', 'I-position', 'B-name', 'B-name', 'B-age', 'B-age', 'I-position', 'I-position', 'B-age', 'I-position', 'I-position', 'O', 'B-age', 'B-age', 'I-name', 'O', 'I-position', 'O', 'B-age', 'I-name', 'B-age', 'B-age', 'I-position', 'B-position', 'B-position', 'B-age', 'B-age', 'B-age', 'I-name', 'B-name', 'B-age', 'O', 'B-position', 'B-age', 'B-name', 'B-name', 'B-age', 'B-age', 'B-age', 'B-age', 'I-name', 'I-name', 'B-age', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2E_z5DWeDIM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c-zw79WBDIQC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}